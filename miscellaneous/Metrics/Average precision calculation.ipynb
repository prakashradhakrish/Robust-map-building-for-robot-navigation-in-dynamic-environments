{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Average precision calculation for the cars between MaskRCNN and SOLOV2\n",
    "## Author: Prakash Radhakrishnan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def iou_metric(prediction,ground_truth):\n",
    "    intersection = np.logical_and(prediction, ground_truth)\n",
    "    union = np.logical_or(prediction, ground_truth)\n",
    "    iou_score = np.sum(intersection) / np.sum(union)\n",
    "    return iou_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def order_image_files(directory):\n",
    "    os.chdir(directory)\n",
    "    images_directory = glob.glob(\"*.png\") # user input of corresponding file\n",
    "    images_directory.sort()\n",
    "    return images_directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "ground_truth_dir = \"/homebackup/dataset/2011_09_30/downloads/Segmentation_evaluation/training/instance/\"\n",
    "#prediction_dir_maskrcnn = \"/home/prakash/datasets/KITTI/kitti_mask/mrcnn_eval/\"\n",
    "prediction_dir = \"/home/prakash/datasets/KITTI/kitti_mask/solo_eval/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:02<00:00, 97.02it/s]\n",
      "100%|██████████| 200/200 [00:02<00:00, 97.39it/s]\n",
      "100%|██████████| 200/200 [00:02<00:00, 97.55it/s]\n",
      "100%|██████████| 200/200 [00:02<00:00, 96.84it/s]\n",
      "100%|██████████| 200/200 [00:02<00:00, 97.45it/s]\n",
      "100%|██████████| 200/200 [00:02<00:00, 95.96it/s]\n",
      "100%|██████████| 200/200 [00:02<00:00, 96.42it/s]\n",
      "100%|██████████| 200/200 [00:02<00:00, 94.61it/s]\n",
      "100%|██████████| 200/200 [00:02<00:00, 75.18it/s]\n",
      "100%|██████████| 200/200 [00:02<00:00, 77.74it/s]\n",
      "100%|██████████| 200/200 [00:02<00:00, 76.74it/s]\n"
     ]
    }
   ],
   "source": [
    "iou_threshold = [0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0] #0.5,0.55,0.6,0.65,0.7,0.75,0.8,0.85,0.9,0.95]\n",
    "iou_metric_value = []\n",
    "for threshold in iou_threshold:\n",
    "    correct_prediction = 0\n",
    "    total_prediction = 0\n",
    "    for singleimage_dir in tqdm(order_image_files(ground_truth_dir)):\n",
    "        image_name = os.path.splitext(os.path.basename(singleimage_dir))[0]\n",
    "        ground_truth_image = os.path.join(ground_truth_dir, str(singleimage_dir))\n",
    "        image_instance= cv2.imread(ground_truth_image)\n",
    "        image_instance[image_instance!=26]=0\n",
    "        image_instance[image_instance==26]=255\n",
    "\n",
    "        prediction_image = prediction_dir + str(image_name) + \"_mask.png\"\n",
    "        prediction = cv2.imread(prediction_image)\n",
    "        prediction[prediction==255]=0\n",
    "        prediction[prediction>10]=255\n",
    "\n",
    "        iou = iou_metric(prediction,image_instance)\n",
    "        total_prediction = total_prediction + 1\n",
    "        if iou > threshold:\n",
    "            correct_prediction = correct_prediction + 1\n",
    "    iou_metric_value.append(correct_prediction/total_prediction)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## old values donot touch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "solo_ap_values = iou_metric_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "mrcnn_ap_values = iou_metric_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AP values of solo 0.5:0.95:0.05 --> [0.965, 0.955, 0.94, 0.94, 0.935, 0.895, 0.805, 0.69, 0.415, 0.05]\n",
      "Mean AP of solo --> 0.7589999999999998\n"
     ]
    }
   ],
   "source": [
    "print(\"AP values of solo 0.5:0.95:0.05 -->\",solo_ap_values)\n",
    "print(\"Mean AP of solo -->\",sum(solo_ap_values)/len(solo_ap_values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AP values of MaskRCNN 0.5:0.95:0.05 --> [0.91, 0.895, 0.875, 0.85, 0.79, 0.695, 0.6, 0.38, 0.07, 0.0]\n",
      "Mean AP of MaskRCNN --> 0.6065\n"
     ]
    }
   ],
   "source": [
    "print(\"AP values of MaskRCNN 0.5:0.95:0.05 -->\",mrcnn_ap_values)\n",
    "print(\"Mean AP of MaskRCNN -->\",sum(mrcnn_ap_values)/len(mrcnn_ap_values))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## New trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "mrcnn_ap_values = iou_metric_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AP values of maskrcnn 0.1:1:0.1 --> [0.995, 0.975, 0.97, 0.96, 0.93, 0.91, 0.875, 0.79, 0.6, 0.07, 0.0]\n",
      "Mean AP of maskrcnn --> 0.7340909090909092\n"
     ]
    }
   ],
   "source": [
    "print(\"AP values of maskrcnn 0.0:1:0.1 -->\",mrcnn_ap_values)\n",
    "print(\"Mean AP of maskrcnn -->\",sum(mrcnn_ap_values)/len(mrcnn_ap_values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AP values of solo 0.0:1:0.1 --> [0.995, 0.995, 0.99, 0.98, 0.98, 0.965, 0.94, 0.935, 0.805, 0.415, 0.0]\n",
      "Mean AP of solo --> 0.818181818181818\n"
     ]
    }
   ],
   "source": [
    "solo_ap_values = iou_metric_value\n",
    "print(\"AP values of solo 0.0:1:0.1 -->\",solo_ap_values)\n",
    "print(\"Mean AP of solo -->\",sum(solo_ap_values)/len(solo_ap_values))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
